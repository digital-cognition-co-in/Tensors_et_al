{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0\n",
      "2.1.2-tf\n",
      "Keras: 2.2.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "### Own - Conda venv --- dc_info_venv\n",
    "### main Source --- https://www.tensorflow.org/guide/\n",
    "\n",
    "# \n",
    "import tensorflow as tf\n",
    "#from tf.keras import layers ### Fails - We have TF version == 1.5.0 \n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework import ops\n",
    "#from tf_utils import load_dataset, random_mini_batches, convert_to_one_hot, predict\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)\n",
    "#\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)\n",
    "import keras\n",
    "print('Keras: {}'.format(keras.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", dtype=float32) Tensor(\"Placeholder_1:0\", dtype=float32) Tensor(\"Sqrt:0\", dtype=float32)\n",
      "4.0 3.0 5.0\n"
     ]
    }
   ],
   "source": [
    "# earlier created Constants \n",
    "# Now creating placeHolders\n",
    "\n",
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "c = tf.sqrt(tf.add(tf.square(a), tf.square(b)))\n",
    "\n",
    "print(a, b, c)\n",
    "\n",
    "sess = tf.Session()\n",
    "print(*sess.run([a, b, c], feed_dict={a: 4., b: 3.}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.0 4.0 18.439089\n"
     ]
    }
   ],
   "source": [
    "print(*sess.run([a, b, c], feed_dict={a: 18., b: 4.}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "## Create a VARIABLE == count_variable\n",
    "\n",
    "count_variable = tf.get_variable(\"count\", [])\n",
    "zero_node = tf.constant(0.)\n",
    "assign_node = tf.assign(count_variable, zero_node)\n",
    "sess = tf.Session()\n",
    "sess.run(assign_node)\n",
    "print(sess.run(count_variable))\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "When a variable node is first created, it basically stores “null”, and any attempts to evaluate it will \n",
    "result in this exception. \n",
    "\n",
    "We can only evaluate a variable after putting a value into it first. \n",
    "There are two main ways to put a value into a variable: initializers and tf.assign(). \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "tf.assign(target, value) is a node that has some unique properties compared to nodes we’ve seen so far:\n",
    "\n",
    "    Identity operation. tf.assign(target, value) does not do any interesting computations, \n",
    "    it is always just equal to value.\n",
    "    \n",
    "    Side effects. When computation “flows” through assign_node, side effects happen to other \n",
    "    things in the graph. \n",
    "    In this case, the side effect is to replace the value of count_variable with the value stored in zero_node.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Non-dependent edges. Even though the count_variable node and the assign_node are connected in the graph, \n",
    "neither is dependent on the other. This means computation will not flow back through that edge when\n",
    "evaluating either node. \n",
    "However, assign_node is dependent on zero_node; it needs to know what to assign.\n",
    "\n",
    "When we call sess.run(assign_node), the computation path goes through assign_node and zero_node.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "As computation flows through any node in the graph, it also enacts any side effects controlled by \n",
    "that node, shown in green. \n",
    "\n",
    "Due to the particular side effects of tf.assign, the memory associated with count_variable \n",
    "(which was previously “null”) is now permanently set to equal 0. \n",
    "This means that when we next call sess.run(count_variable), \n",
    "we don’t throw any exceptions. Instead, we get a value of 0. Success!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable count already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"<ipython-input-7-6122986dbb8d>\", line 3, in <module>\n    count_variable = tf.get_variable(\"count\", [])\n  File \"/home/dhankar/anaconda2/envs/dc_info_venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/home/dhankar/anaconda2/envs/dc_info_venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a8f4e21b064e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconst_init_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcount_variable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"count\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconst_init_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount_variable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/dc_info_venv/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1260\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1262\u001b[0;31m       constraint=constraint)\n\u001b[0m\u001b[1;32m   1263\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m   1264\u001b[0m     \"\"\"%s\n",
      "\u001b[0;32m~/anaconda2/envs/dc_info_venv/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1095\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m           \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/anaconda2/envs/dc_info_venv/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m    433\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m           \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[0;32m~/anaconda2/envs/dc_info_venv/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    402\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m           use_resource=use_resource, constraint=constraint)\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/dc_info_venv/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    741\u001b[0m                          \u001b[0;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 743\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    744\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable count already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"<ipython-input-7-6122986dbb8d>\", line 3, in <module>\n    count_variable = tf.get_variable(\"count\", [])\n  File \"/home/dhankar/anaconda2/envs/dc_info_venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/home/dhankar/anaconda2/envs/dc_info_venv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n"
     ]
    }
   ],
   "source": [
    "### Initializers ---\n",
    "\n",
    "const_init_node = tf.constant_initializer(0.)\n",
    "count_variable = tf.get_variable(\"count\", [], initializer=const_init_node) #\n",
    "## above -- initializer , is a PROPERTY of tf.get_variable.\n",
    "## its been set to --- const_init_node\n",
    "## We have created a CONNECTION in the GRAPH between Two Nodes \n",
    "## We are yet --- to tell the SESSION - which is not communicating with the GRAPH ..\n",
    "## We tell SESSION whats to be done - by CODE LINE == init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "print(sess.run([count_variable]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0]\n"
     ]
    }
   ],
   "source": [
    "const_init_node = tf.constant_initializer(0.)\n",
    "count_variable = tf.get_variable(\"count\", [], initializer=const_init_node)\n",
    "#count_variable = tf.get_variable(\"count\", [], initializer=const_init_node ,reuse=True) \n",
    "## reuse=True -- wont work here \n",
    "## restarting Notebook ..then below works...as count_variable - which was INIT in cell above, can be INIT again.\n",
    "\n",
    "init = tf.global_variables_initializer() # Another node with side-effects...\n",
    "## https://www.tensorflow.org/api_docs/python/tf/initializers/global_variables\n",
    "## RETURNS -- An Op that initializes global variables in the graph.\n",
    "## this - global_var_INIT - will look at the Global Graph and Add dependencies to each -- tf.initializer - that it finds.\n",
    "## by - dependencies - here we mean it will make them -- RE-INIT all the Variables. \n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run([count_variable]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Variable Sharing --- Source -- https://jacobbuckman.com/post/tensorflow-the-confusing-parts-1/#fnref:1\n",
    "#\n",
    "\"\"\"\n",
    "You may encounter Tensorflow code with variable sharing, which involves creating a scope \n",
    "and setting “reuse=True”. \n",
    "\n",
    "I strongly recommend that you don’t use this in your own code.\n",
    "If you want to use a single variable in multiple places, simply keep track of your pointer to that \n",
    "variable’s node programmatically, and re-use it when you need to. \n",
    "In other words, you should have only a single call of tf.get_variable() for each parameter you \n",
    "intend to store in memory.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Optimizers -- Source -- https://jacobbuckman.com/post/tensorflow-the-confusing-parts-1/#fnref:1\n",
    "\n",
    "\"\"\"\n",
    "At last: on to the actual deep learning! If you’re still with me, the remaining concepts should be extremely straightforward.\n",
    "\n",
    "In deep learning, the typical “inner loop” of training is as follows:\n",
    "\n",
    "    Get an input and true_output\n",
    "    Compute a “guess” based on the input and your parameters\n",
    "    Compute a “loss” based on the difference between your guess and the true_output\n",
    "    Update the parameters according to the gradient of the loss\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nValueError: Variable m already exists, disallowed. \\nDid you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### build the graph\n",
    "## first set up the parameters\n",
    "m = tf.get_variable(\"m\", [], initializer=tf.constant_initializer(0.))\n",
    "b = tf.get_variable(\"b\", [], initializer=tf.constant_initializer(0.))\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "## then set up the computations\n",
    "input_placeholder = tf.placeholder(tf.float32)\n",
    "output_placeholder = tf.placeholder(tf.float32)\n",
    "\n",
    "x = input_placeholder\n",
    "y = output_placeholder\n",
    "y_guess = m * x + b\n",
    "\n",
    "loss = tf.square(y - y_guess)\n",
    "### FATT --- Dont RE-RUN this cell again --- Re-start Notebook\n",
    "\"\"\"\n",
    "ValueError: Variable m already exists, disallowed. \n",
    "Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## finally, set up the optimizer and minimization node\n",
    "optimizer = tf.train.GradientDescentOptimizer(1e-3)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "### start the session\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "### perform the training loop\n",
    "import random\n",
    "\n",
    "## set up problem\n",
    "true_m = random.random()\n",
    "true_b = random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True parameters: m=, b= 0.9824292379701893 0.11241916250550743\n",
      "Learned parameters:  m=, b= (0.9824003, 0.11243391)\n"
     ]
    }
   ],
   "source": [
    "for update_i in range(100000):\n",
    "    #\n",
    "    \n",
    "    ## (1) get the input and output\n",
    "    input_data = random.random()\n",
    "    output_data = true_m * input_data + true_b\n",
    "\n",
    "    ## (2), (3), and (4) all take place within a single call to sess.run()!\n",
    "    _loss, _ = sess.run([loss, train_op], feed_dict={input_placeholder: input_data, output_placeholder: output_data})\n",
    "    #print(update_i, _loss) ## Dont Print ...\n",
    "\n",
    "### finally, print out the values we learned for our two variables\n",
    "#print(\"True parameters:     m=%.4f, b=%.4f\", % (true_m, true_b))\n",
    "print(\"True parameters: m=, b=\",true_m, true_b)\n",
    "#print(\"Learned parameters:  m=%.4f, b=%.4f\", % tuple(sess.run([m, b])))\n",
    "print(\"Learned parameters:  m=, b=\",tuple(sess.run([m, b])))\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "0 0.8164941\n",
    "1 1.1643778\n",
    "2 0.8676618\n",
    "3 1.1011628\n",
    "4 1.3437326\n",
    "5 0.79393685\n",
    "6 0.7909982\n",
    "7 0.7743486\n",
    "8 0.9102865\n",
    "9 0.9251575\n",
    "10 1.3213344\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dc_info_venv]",
   "language": "python",
   "name": "conda-env-dc_info_venv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
